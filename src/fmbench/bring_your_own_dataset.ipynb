{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d144a1ec-e66d-45b8-baf1-af4641ee23ce",
   "metadata": {},
   "source": [
    "# Bring your own dataset\n",
    "\n",
    "---------\n",
    "*This notebook works best with the conda_python3 kernel on a ml.t3.medium machine*.\n",
    "\n",
    "### This part of our solution design includes \n",
    "\n",
    "- Creating your own `fmbench` compatible dataset from a [HuggingFace dataset](https://huggingface.co/docs/datasets/en/index).\n",
    "\n",
    "- Creating a prompt payload template compatible with your dataset.\n",
    "\n",
    "- Upload the dataset and the prompt payload to Amazon S3 from where it can be used by `fmbench`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eafa135b-2dec-4e2c-9821-bd8268a21492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if interactive mode is set to no -> pickup fmbench from Python installation path\n",
    "# if interactive mode is set to yes -> pickup fmbench from the current path (one level above this notebook)\n",
    "# if interactive mode is not defined -> pickup fmbench from the current path (one level above this notebook)\n",
    "# the premise is that if run non-interactively then it can only be run through main.py which will set interactive mode to no\n",
    "import os\n",
    "import sys\n",
    "if os.environ.get(\"INTERACTIVE_MODE_SET\", \"yes\") == \"yes\":\n",
    "    sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7343d0fb-89cc-48da-8c77-22b8024a7e94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_name=us-west-2\n",
      "role_arn_from_env=None, using current sts caller identity to set arn_string\n",
      "the sts role is an assumed role, setting arn_string to arn:aws:iam::988564344122:role/fmbench-stack-us-west-2-role\n",
      "config file current -> configs/llama3.1/8b/config-llama3.1-8b-g5.yml, None\n",
      "loaded config: {'general': {'name': 'Llama3-1-8b-g5', 'model_name': 'Llama3-1-8b'}, 'aws': {'region': 'us-west-2', 'sagemaker_execution_role': 'arn:aws:iam::988564344122:role/fmbench-stack-us-west-2-role', 'bucket': 'sagemaker-fmbench-write-us-west-2-988564344122'}, 'dir_paths': {'data_prefix': 'data', 'prompts_prefix': 'prompts', 'all_prompts_file': 'all_prompts.csv', 'metrics_dir': 'metrics', 'models_dir': 'models', 'metadata_dir': 'metadata'}, 's3_read_data': {'read_bucket': 'sagemaker-fmbench-read-us-west-2-988564344122', 'scripts_prefix': 'scripts', 'script_files': ['hf_token.txt'], 'configs_prefix': 'configs', 'config_files': ['pricing.yml'], 'source_data_prefix': 'source_data', 'source_data_files': ['2wikimqa_e.jsonl', '2wikimqa.jsonl', 'hotpotqa_e.jsonl', 'hotpotqa.jsonl', 'narrativeqa.jsonl', 'triviaqa_e.jsonl', 'triviaqa.jsonl'], 'tokenizer_prefix': 'llama3_1_tokenizer', 'prompt_template_dir': 'prompt_template', 'prompt_template_file': 'prompt_template_llama3.txt'}, 'run_steps': {'0_setup.ipynb': True, '1_generate_data.ipynb': True, '2_deploy_model.ipynb': True, '3_run_inference.ipynb': True, '4_get_evaluations.ipynb': True, '5_model_metric_analysis.ipynb': True, '6_cleanup.ipynb': True}, 'datasets': {'prompt_template_keys': ['input', 'context'], 'ground_truth_col_key': 'answers', 'question_col_key': 'input', 'filters': [{'language': 'en', 'min_length_in_tokens': 1, 'max_length_in_tokens': 500, 'payload_file': 'payload_en_1-500.jsonl'}, {'language': 'en', 'min_length_in_tokens': 500, 'max_length_in_tokens': 1000, 'payload_file': 'payload_en_500-1000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 1000, 'max_length_in_tokens': 2000, 'payload_file': 'payload_en_1000-2000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 2000, 'max_length_in_tokens': 3000, 'payload_file': 'payload_en_2000-3000.jsonl'}, {'language': 'en', 'min_length_in_tokens': 3000, 'max_length_in_tokens': 3840, 'payload_file': 'payload_en_3000-3840.jsonl'}]}, 'model_evaluations': 'model_eval_all_info.yml', 'metrics': {'dataset_of_interest': 'en_3000-3840'}, 'pricing': 'pricing.yml', 'inference_parameters': {'sagemaker': {'do_sample': True, 'temperature': 0.1, 'top_p': 0.92, 'top_k': 120, 'max_new_tokens': 100}}, 'experiments': [{'name': 'Llama3-1-8b-g5.12xl-djl-inference:0.29.0-lmi11.0.0-cu124', 'model_id': 'meta-llama/Llama-3.1-8B-Instruct', 'model_version': '*', 'model_name': 'Meta-Llama-3-1-8B-Instruct', 'ep_name': 'Meta-Llama-3-1-8B-Instruct-g5-12xl', 'download_from_hf_place_in_s3': False, 'model_s3_path': 's3://sagemaker-fmbench-write-us-west-2-988564344122/meta-llama/Meta-Llama-3-1-8B-Instruct', 'instance_type': 'ml.g5.12xlarge', 'image_uri': '763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124', 'deploy': True, 'instance_count': 1, 'deployment_script': 'deploy_w_djl_serving.py', 'inference_script': 'sagemaker_predictor.py', 'inference_spec': {'parameter_set': 'sagemaker', 'parameters': {'do_sample': True, 'temperature': 0.1, 'top_p': 0.92, 'top_k': 120, 'max_new_tokens': 100}}, 'serving.properties': 'engine=Python\\noption.model_id=s3://sagemaker-fmbench-write-us-west-2-988564344122/meta-llama/Meta-Llama-3.1-8B-Instruct\\noption.dtype=fp16\\n', 'payload_files': ['payload_en_1-500.jsonl', 'payload_en_500-1000.jsonl', 'payload_en_1000-2000.jsonl', 'payload_en_2000-3000.jsonl', 'payload_en_3000-3840.jsonl'], 'concurrency_levels': [1, 2, 4, 10], 'accept_eula': True, 'env': None, 'bucket': 'sagemaker-fmbench-write-us-west-2-988564344122'}, {'name': 'Llama3-1-8b-g5.24xl-djl-inference:0.29.0-lmi11.0.0-cu124', 'model_id': 'meta-llama/Llama-3.1-8B-Instruct', 'model_version': '*', 'model_name': 'Meta-Llama-3-1-8B-Instruct', 'ep_name': 'Meta-Llama-3-1-8B-Instruct-g5-24xl', 'download_from_hf_place_in_s3': False, 'model_s3_path': 's3://sagemaker-fmbench-write-us-west-2-988564344122/meta-llama/Meta-Llama-3-1-8B-Instruct', 'instance_type': 'ml.g5.24xlarge', 'image_uri': '763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124', 'deploy': True, 'instance_count': 1, 'deployment_script': 'deploy_w_djl_serving.py', 'inference_script': 'sagemaker_predictor.py', 'inference_spec': {'parameter_set': 'sagemaker', 'parameters': {'do_sample': True, 'temperature': 0.1, 'top_p': 0.92, 'top_k': 120, 'max_new_tokens': 100}}, 'serving.properties': 'engine=Python\\noption.model_id=s3://sagemaker-fmbench-write-us-west-2-988564344122/meta-llama/Meta-Llama-3.1-8B-Instruct\\noption.dtype=fp16\\n', 'payload_files': ['payload_en_1-500.jsonl', 'payload_en_500-1000.jsonl', 'payload_en_1000-2000.jsonl', 'payload_en_2000-3000.jsonl', 'payload_en_3000-3840.jsonl'], 'concurrency_levels': [1, 2, 4, 10], 'accept_eula': True, 'env': None, 'bucket': 'sagemaker-fmbench-write-us-west-2-988564344122'}, {'name': 'Llama3-1-8b-g5.48xl-djl-inference:0.29.0-lmi11.0.0-cu124', 'model_id': 'meta-llama/Llama-3.1-8B-Instruct', 'model_version': '*', 'model_name': 'Meta-Llama-3-1-8B-Instruct', 'ep_name': 'Meta-Llama-3-1-8B-Instruct-g5-48xl', 'download_from_hf_place_in_s3': False, 'model_s3_path': 's3://sagemaker-fmbench-write-us-west-2-988564344122/meta-llama/Meta-Llama-3-1-8B-Instruct', 'instance_type': 'ml.g5.48xlarge', 'image_uri': '763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124', 'deploy': True, 'instance_count': 1, 'deployment_script': 'deploy_w_djl_serving.py', 'inference_script': 'sagemaker_predictor.py', 'inference_spec': {'parameter_set': 'sagemaker', 'parameters': {'do_sample': True, 'temperature': 0.1, 'top_p': 0.92, 'top_k': 120, 'max_new_tokens': 100}}, 'serving.properties': 'engine=Python\\noption.model_id=s3://sagemaker-fmbench-write-us-west-2-988564344122/meta-llama/Meta-Llama-3.1-8B-Instruct\\noption.dtype=fp16\\n', 'payload_files': ['payload_en_1-500.jsonl', 'payload_en_500-1000.jsonl', 'payload_en_1000-2000.jsonl', 'payload_en_2000-3000.jsonl', 'payload_en_3000-3840.jsonl'], 'concurrency_levels': [1, 2, 4, 10], 'accept_eula': True, 'env': None, 'bucket': 'sagemaker-fmbench-write-us-west-2-988564344122'}], 'report': {'latency_budget': 2, 'cost_per_10k_txn_budget': 50, 'error_rate_budget': 0, 'per_inference_request_file': 'per_inference_request_results.csv', 'all_metrics_file': 'all_metrics.csv', 'txn_count_for_showing_cost': 10000, 'v_shift_w_single_instance': 0.025, 'v_shift_w_gt_one_instance': 0.025, 'latency_vs_token_len_chart': {'y_ticks': None, 'title': 'Effect of token length on inference latency for \"meta-llama/Meta-Llama-3.1-8B-Instruct\"'}}}\n",
      "loaded eval configuration file: {'model_evaluations': {'ground_truth_col': {'ground_truth': None}, 'question_col': {'question': None}, 'PoLL_Composition_and_Voting': {'method': 'majority_vote', 'use_quantitative_metrics': True}, 'model_eval_dir': {'eval_prompts_dir': 'eval_criteria', 'eval_prompt_template_dir_list': ['claude_eval_prompt_templates', 'llama3_eval_prompt_templates', 'cohere_eval_prompt_templates', 'mistral_eval_prompt_templates'], 'eval_instructions_dir': 'eval_instructions', 'eval_instructions_files': ['evaluation_instructions_majority_vote.txt']}, 'quantitative_eval_info': {'embeddings_model_id': {'model_id': 'sentence-transformers/all-mpnet-base-v2'}, 'incorrect_verdict_cosine_similarity_threshold': 0.4, 'correct_verdict_cosine_similarity_threshold': 0.01}, 'subjective_eval_info': {'judge_panel_list': [{'model_id': 'meta.llama3-70b-instruct-v1:0', 'eval_prompt_template_dir': 'llama3_eval_prompt_templates', 'eval_prompt_template_name': 'llama3_eval_{method_name}'}, {'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0', 'eval_prompt_template_dir': 'claude_eval_prompt_templates', 'eval_prompt_template_name': 'claude_eval_{method_name}'}, {'model_id': 'cohere.command-r-plus-v1:0', 'eval_prompt_template_dir': 'cohere_eval_prompt_templates', 'eval_prompt_template_name': 'cohere_eval_{method_name}'}], 'run_parallel_inference_count': 10, 'inference_parameters': {'temperature': 0.1, 'max_tokens': 300, 'top_p': 0.92, 'caching': False}}}}\n",
      "/home/ec2-user/anaconda3/envs/fmbench_python311/lib/python3.11/site-packages/fmbench/scripts/hf_token.txt file not found\n",
      "CustomTokenizer, based on HF transformers, sagemaker-fmbench-read-us-west-2-988564344122 prefix: llama3_1_tokenizer local_dir: tokenizer, model_id: meta-llama/Llama-3.1-8B-Instruct\n",
      "CustomTokenizer, all_files = [PosixPath('tokenizer/tokenizer.json'), PosixPath('tokenizer/config.json'), PosixPath('tokenizer/tokenizer_config.json')]\n",
      "loading the provided tokenizer from local_dir=tokenizer, abs_path=/home/ec2-user/SageMaker/multimodal-fmbench/foundation-model-benchmarking-tool/src/fmbench/tokenizer\n",
      "successfully loaded the tokenizer using AutoTokenizer.from_pretrained from tokenizer\n",
      "region_name=us-west-2\n",
      "role_arn_from_env=None, using current sts caller identity to set arn_string\n",
      "the sts role is an assumed role, setting arn_string to arn:aws:iam::988564344122:role/fmbench-stack-us-west-2-role\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fmbench.utils import *\n",
    "from fmbench.globals import *\n",
    "from datasets import load_dataset\n",
    "config = load_config(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89998f93-e59a-4d47-9957-ad0b11a089f7",
   "metadata": {},
   "source": [
    "## Convert HuggingFace dataset to jsonl format\n",
    "\n",
    "`fmbench` works with datasets in the [`JSON Lines`](https://jsonlines.org/) format. So here we show how to convert a HuggingFace dataset into JSON lines format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d021d-ff1c-4275-85ae-128265b0d5fa",
   "metadata": {},
   "source": [
    "Set the `ds_name` to the HuggingFace dataset id, for example [`THUDM/LongBench`](https://huggingface.co/datasets/THUDM/LongBench), [`rajpurkar/squad_v2`](https://huggingface.co/datasets/rajpurkar/squad_v2), [`banking77`](https://huggingface.co/datasets/banking77) or other text datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "657bad51-f5dd-45e0-a08c-cbfd33206301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_id: str = \"rajpurkar/squad\"\n",
    "ds_name: str = \"plain_text\"\n",
    "ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "ds_N: int = 100\n",
    "\n",
    "# another example\n",
    "# ds_id: str = \"THUDM/LongBench\"\n",
    "# ds_name: str = \"2wikimqa\"\n",
    "# ds_split: str = \"test\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "# ds_N: int = 200\n",
    "\n",
    "# another example\n",
    "# ds_id: str = \"banking77\"\n",
    "# ds_name: str = \"default\"\n",
    "# ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "# ds_N: int = 10000\n",
    "\n",
    "ds_id: str = \"Open-Orca/OpenOrca\"\n",
    "ds_name: str = \"default\"\n",
    "ds_split: str = \"train\"\n",
    "# Take a random subset of the dataframe, adjust the value of `N` below as appropriate.\n",
    "# size of random subset of the data\n",
    "ds_N: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "707c44bd-af91-4268-9d76-35544b0653e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset from huggingface\n",
    "dataset = load_dataset(ds_id, name=ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086ac1e1-15dd-427b-83c7-10e858695c5e",
   "metadata": {},
   "source": [
    "### For image datasets\n",
    "---\n",
    "\n",
    "In this section of the notebook, we will use an image dataset, convert the images into `base64` and then send the relevant data to s3/locally that will be used during the benchmarking test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f36d56a4-b3a2-44eb-8fc2-dfa0900c1abe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75483aaae2cc48bd8210d3f30c8568bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/738 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569618dc23f14eba8e62e30c0b0e1788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/738 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import itertools\n",
    "\n",
    "ds_id: str = \"HuggingFaceM4/WebSight\"\n",
    "ds_name: str = \"v0.2\"\n",
    "ds_split: str = \"train\"\n",
    "ds_N: int = 100\n",
    "\n",
    "# Load the dataset in streaming mode so you don't have to load the entire dataset\n",
    "dataset = load_dataset(ds_id, name=ds_name, split=ds_split, streaming=True)\n",
    "\n",
    "# Take only the first ds_N examples\n",
    "dataset_iter = itertools.islice(dataset, ds_N)\n",
    "\n",
    "# Convert to a list and then to a regular dataset\n",
    "dataset_list = list(dataset_iter)\n",
    "dataset = Dataset.from_list(dataset_list)\n",
    "\n",
    "logger.info(f\"Loaded {len(dataset)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e558518a-c24e-4f6d-becf-3fdbf6c10e78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text', 'llm_generated_idea'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b537258-4b82-4fc3-9428-aed84dbe6f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the dataset to a dataframe, for print it out and easy conversion to jsonl\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5211187-d4b4-4104-b289-e8cd98782387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     <PIL.JpegImagePlugin.JpegImageFile image mode=...\n",
       "1     <PIL.JpegImagePlugin.JpegImageFile image mode=...\n",
       "2     <PIL.JpegImagePlugin.JpegImageFile image mode=...\n",
       "3     <PIL.JpegImagePlugin.JpegImageFile image mode=...\n",
       "4     <PIL.JpegImagePlugin.JpegImageFile image mode=...\n",
       "                            ...                        \n",
       "95    <PIL.JpegImagePlugin.JpegImageFile image mode=...\n",
       "96    <PIL.JpegImagePlugin.JpegImageFile image mode=...\n",
       "97    <PIL.JpegImagePlugin.JpegImageFile image mode=...\n",
       "98    <PIL.JpegImagePlugin.JpegImageFile image mode=...\n",
       "99    <PIL.JpegImagePlugin.JpegImageFile image mode=...\n",
       "Name: image, Length: 100, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5cb193a-3bc3-42e2-94aa-342a13108bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>llm_generated_idea</th>\n",
       "      <th>image_base64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>&lt;html&gt;\\n&lt;link href=\"https://cdn.jsdelivr.net/n...</td>\n",
       "      <td>Fashion Brand: A visually stunning layout with...</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>&lt;html&gt;\\n&lt;link href=\"https://cdn.jsdelivr.net/n...</td>\n",
       "      <td>Restaurant Chain: A design with a mouth-wateri...</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>&lt;html&gt;\\n&lt;link href=\"https://cdn.jsdelivr.net/n...</td>\n",
       "      <td>Consulting Firm: A clean, professional design ...</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>&lt;html&gt;\\n&lt;link href=\"https://cdn.jsdelivr.net/n...</td>\n",
       "      <td>Real Estate Agency: A user-friendly design wit...</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>&lt;html&gt;\\n&lt;link href=\"https://cdn.jsdelivr.net/n...</td>\n",
       "      <td>Education Platform: A design with a wide, hero...</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  \\\n",
       "0  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "1  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "2  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "3  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "4  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "\n",
       "                                                text  \\\n",
       "0  <html>\\n<link href=\"https://cdn.jsdelivr.net/n...   \n",
       "1  <html>\\n<link href=\"https://cdn.jsdelivr.net/n...   \n",
       "2  <html>\\n<link href=\"https://cdn.jsdelivr.net/n...   \n",
       "3  <html>\\n<link href=\"https://cdn.jsdelivr.net/n...   \n",
       "4  <html>\\n<link href=\"https://cdn.jsdelivr.net/n...   \n",
       "\n",
       "                                  llm_generated_idea  \\\n",
       "0  Fashion Brand: A visually stunning layout with...   \n",
       "1  Restaurant Chain: A design with a mouth-wateri...   \n",
       "2  Consulting Firm: A clean, professional design ...   \n",
       "3  Real Estate Agency: A user-friendly design wit...   \n",
       "4  Education Platform: A design with a wide, hero...   \n",
       "\n",
       "                                        image_base64  \n",
       "0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "1  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "2  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "3  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "4  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def image_to_base64(img):\n",
    "    buffered = io.BytesIO()\n",
    "    img.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# Create the new base64 column\n",
    "df['image_base64'] = df['image'].apply(image_to_base64)\n",
    "\n",
    "# Now df has a new column 'image_base64' with the base64 encoded images\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af2c2f53-f456-46bb-8bb6-801ae6a951aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>llm_generated_idea</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>&lt;html&gt;\\n&lt;link href=\"https://cdn.jsdelivr.net/n...</td>\n",
       "      <td>Fashion Brand: A visually stunning layout with...</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>&lt;html&gt;\\n&lt;link href=\"https://cdn.jsdelivr.net/n...</td>\n",
       "      <td>Restaurant Chain: A design with a mouth-wateri...</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>&lt;html&gt;\\n&lt;link href=\"https://cdn.jsdelivr.net/n...</td>\n",
       "      <td>Consulting Firm: A clean, professional design ...</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>&lt;html&gt;\\n&lt;link href=\"https://cdn.jsdelivr.net/n...</td>\n",
       "      <td>Real Estate Agency: A user-friendly design wit...</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>&lt;html&gt;\\n&lt;link href=\"https://cdn.jsdelivr.net/n...</td>\n",
       "      <td>Education Platform: A design with a wide, hero...</td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  \\\n",
       "0  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "1  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "2  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "3  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "4  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "\n",
       "                                                text  \\\n",
       "0  <html>\\n<link href=\"https://cdn.jsdelivr.net/n...   \n",
       "1  <html>\\n<link href=\"https://cdn.jsdelivr.net/n...   \n",
       "2  <html>\\n<link href=\"https://cdn.jsdelivr.net/n...   \n",
       "3  <html>\\n<link href=\"https://cdn.jsdelivr.net/n...   \n",
       "4  <html>\\n<link href=\"https://cdn.jsdelivr.net/n...   \n",
       "\n",
       "                                  llm_generated_idea  \\\n",
       "0  Fashion Brand: A visually stunning layout with...   \n",
       "1  Restaurant Chain: A design with a mouth-wateri...   \n",
       "2  Consulting Firm: A clean, professional design ...   \n",
       "3  Real Estate Agency: A user-friendly design wit...   \n",
       "4  Education Platform: A design with a wide, hero...   \n",
       "\n",
       "                                               input  \n",
       "0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "1  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "2  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "3  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
       "4  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some datasets contain a field called column, we would like to call it\n",
    "# input to match it to the prompt template\n",
    "df.rename(columns={\"image_base64\": \"input\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703cc0f9-a86b-42de-81b4-21a6a3048fe7",
   "metadata": {},
   "source": [
    "### Subset the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30c4e481-2cd4-4341-b910-c5172eafe400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape before random subset = (100, 4)\n",
      "dataset shape before random subset = (100, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset shape before random subset = {df.shape}\")\n",
    "df = df.sample(n=ds_N)\n",
    "print(f\"dataset shape before random subset = {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7fcadf-0ca7-4123-92d6-ed7b188cfd4b",
   "metadata": {},
   "source": [
    "Convert to json lines format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adb38f44-9788-4d26-b77e-2dde3feddfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"image\":{\"app\":{\"APP0\":\"JFIF\\u0000\\u0001\\u0001\\u0000\\u0000\\u0001\\u0000\\u0001\\u0000\\u0000\"},\"applist\":[[\"APP0\",\"JFIF\\u0000\\u0001\\u0001\\u0000\\u0000\\u0001\\u0000\\u0001\\u0000\\u0000\"]],\"bits\":8,\"custom_mimetype\":null,\"decoderconfig\":[],\"decodermaxblock\":65536,\"encoderconfig\":[-1,false,0,false,false,0,0,0,-1,0,0,null,null,\"\",\"\"],\"encoderinfo\":{},\"filename\":\"\",\"format\":\"JPEG\",\"format_description\":\"JPEG (ISO 10918)\",\"fp\":null,\"has_transparency_data\":false,\"height\":1440,\"huffman_ac\":{},\"huffman_dc\":{},\"icclist\":[],\"im\":{\"bands\":3,\"id\":94323468030944,\"mode\":\"RGB\",\"ptr\":{},\"size\":[2560,1440],\"unsafe_ptrs\":[[\"image8\",0],[\"image32\",94331769226096],[\"image\",94331769226096]]},\"info\":{\"jfif\":257,\"jfif_version\":[1,1],\"jfif_unit\":0,\"jfif_density\":[1,1]},\"layer\":[[1,2,2,0],[2,1,1,1],[3,1,1,1]],\"layers\":3,\"map\":null,\"mode\":\"RGB\",\"palette\":null,\"pyaccess\":null,\"quantization\":{\"0\":[8,6,5,8,12,20,26,31,6,6,7,10,13,29,30,28,7,7,8,12,20,29,35,28,7,9,11,15,26,44,40,31,9,11,19,28,34,55,52,39,12,18,28,32,41,52,57\n"
     ]
    }
   ],
   "source": [
    "jsonl_content = df.to_json(orient='records', lines=True)\n",
    "print(jsonl_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c64b4-d0c8-41d5-80a2-86581d176a20",
   "metadata": {},
   "source": [
    "## Upload the dataset to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0bfecbb1-6355-4f52-86a4-53579d867629",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-fmbench-read-us-west-2-988564344122/source_data/HuggingFaceM4/WebSight.jsonl'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket: str = config['s3_read_data']['read_bucket']\n",
    "prefix: str = config['s3_read_data']['source_data_prefix']\n",
    "file_name: str = f\"{ds_id}.jsonl\"\n",
    "write_to_s3(jsonl_content, bucket, prefix, \"\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6fd45-fc80-45f3-a184-9cad6a1cd706",
   "metadata": {},
   "source": [
    "## Create a prompt template and upload it to S3\n",
    "The prompt template is specific to the model under test and also the dataset being used. The variables used in the template, such as `context` and `input` must exist in the dataset being used so that this prompt template can be converted into an actual prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "018df5ca-dd8a-4436-a1a6-c3204ac079d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dictionary containing the prompt template, it has a key by the name\n",
    "# of the dataset id which forces you to explicitly add your dataset here\n",
    "# otherwise no new prompt template will be uploaded and it wont accidently\n",
    "# end up overwriting an existing prompt template\n",
    "prompt_template = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef34360-c855-49e6-a624-0209ba09939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LongBench\n",
    "prompt_template['THUDM-LongBench-llama2-mistral'] = \"\"\"<s>[INST] <<SYS>>\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context in the section demarcated by \"```\" to answer the question. If you don't know the answer just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "<</SYS>>\n",
    "\n",
    "```\n",
    "{context}\n",
    "```\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "[/INST]\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac185446-2338-47ec-8c78-30dea736aaec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open Orca\n",
    "prompt_template['Open-Orca-OpenOrca-llama2-mistral'] = \"\"\"<s>[INST] <<SYS>>\n",
    "\n",
    "{system_prompt}\n",
    "\n",
    "<</SYS>>\n",
    "\n",
    "Context and task: {input}\n",
    "\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0009c-79b8-4cf9-8450-824a03ae5996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template['Open-Orca-OpenOrca-llama3'] = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{system_prompt}\n",
    "\n",
    "Context and task: {input} \n",
    "\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771c28e-07c6-4805-b33d-186895496aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket: str = config['s3_read_data']['read_bucket']\n",
    "prefix: str = config['s3_read_data']['prompt_template_dir']\n",
    "for k in prompt_template.keys():\n",
    "    file_name: str = f\"prompt_template_{k}.txt\"\n",
    "    print(f\"writing {file_name} to s3://{bucket}/{prefix}/{file_name}\")\n",
    "    write_to_s3(prompt_template[k], bucket, prefix, \"\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a25ebd9-782a-4765-b612-2731468c5d63",
   "metadata": {},
   "source": [
    "## Scratchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d11fdc-ac92-42a7-b9de-8a5d36050532",
   "metadata": {},
   "source": [
    "### Utility function for converting a line from container log to JSON format\n",
    "\n",
    "The following is a line from CW log from a model container that provides all the information about the model that is not available anywhere else (not in Model or EndpointConfig or Endpoint description). This information is often necessary to know the low level settings about the model which may have been set while compiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71becec-c2c7-4145-ad9d-84ab16e79aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id_or_path='/tmp/.djl.ai/download/ae03dd100c208acd82b5dbed563c971de864c408'\n",
      "rolling_batch=<RollingBatchEnum.auto: 'auto'>\n",
      "tensor_parallel_degree=8\n",
      "trust_remote_code=False\n",
      "enable_streaming=<StreamingEnum.false: 'false'>\n",
      "batch_size=4\n",
      "max_rolling_batch_size=4\n",
      "dtype=<Dtype.f16: 'fp16'>\n",
      "revision=None\n",
      "output_formatter=None\n",
      "waiting_steps=None\n",
      "is_mpi=False\n",
      "draft_model_id=None\n",
      "spec_length=0\n",
      "neuron_optimize_level=None\n",
      "enable_mixed_precision_accumulation=False\n",
      "enable_saturate_infinity=False\n",
      "n_positions=4096\n",
      "unroll=None\n",
      "load_in_8bit=False\n",
      "low_cpu_mem_usage=False\n",
      "load_split_model=True\n",
      "context_length_estimate=None\n",
      "amp='f16'\n",
      "quantize=None\n",
      "compiled_graph_path=None\n",
      "task=None\n",
      "save_mp_checkpoint_path=None\n",
      "group_query_attention=None\n",
      "model_loader=<TnXModelLoaders.tnx: 'tnx'>\n",
      "rolling_batch_strategy=<TnXGenerationStrategy.continuous_batching: 'continuous_batching'>\n",
      "fuse_qkv=False\n",
      "on_device_embedding=False\n",
      "attention_layout=None\n",
      "collectives_layout=None\n",
      "cache_layout=None\n",
      "partition_schema=None\n",
      "all_reduce_dtype=None\n",
      "cast_logits_dtype=None\n",
      "{\n",
      "  \"model_id_or_path\": \"'/tmp/.djl.ai/download/ae03dd100c208acd82b5dbed563c971de864c408'\",\n",
      "  \"rolling_batch\": \"<RollingBatchEnum.auto: 'auto'>\",\n",
      "  \"tensor_parallel_degree\": \"8\",\n",
      "  \"trust_remote_code\": \"False\",\n",
      "  \"enable_streaming\": \"<StreamingEnum.false: 'false'>\",\n",
      "  \"batch_size\": \"4\",\n",
      "  \"max_rolling_batch_size\": \"4\",\n",
      "  \"dtype\": \"<Dtype.f16: 'fp16'>\",\n",
      "  \"revision\": \"None\",\n",
      "  \"output_formatter\": \"None\",\n",
      "  \"waiting_steps\": \"None\",\n",
      "  \"is_mpi\": \"False\",\n",
      "  \"draft_model_id\": \"None\",\n",
      "  \"spec_length\": \"0\",\n",
      "  \"neuron_optimize_level\": \"None\",\n",
      "  \"enable_mixed_precision_accumulation\": \"False\",\n",
      "  \"enable_saturate_infinity\": \"False\",\n",
      "  \"n_positions\": \"4096\",\n",
      "  \"unroll\": \"None\",\n",
      "  \"load_in_8bit\": \"False\",\n",
      "  \"low_cpu_mem_usage\": \"False\",\n",
      "  \"load_split_model\": \"True\",\n",
      "  \"context_length_estimate\": \"None\",\n",
      "  \"amp\": \"'f16'\",\n",
      "  \"quantize\": \"None\",\n",
      "  \"compiled_graph_path\": \"None\",\n",
      "  \"task\": \"None\",\n",
      "  \"save_mp_checkpoint_path\": \"None\",\n",
      "  \"group_query_attention\": \"None\",\n",
      "  \"model_loader\": \"<TnXModelLoaders.tnx: 'tnx'>\",\n",
      "  \"rolling_batch_strategy\": \"<TnXGenerationStrategy.continuous_batching: 'continuous_batching'>\",\n",
      "  \"fuse_qkv\": \"False\",\n",
      "  \"on_device_embedding\": \"False\",\n",
      "  \"attention_layout\": \"None\",\n",
      "  \"collectives_layout\": \"None\",\n",
      "  \"cache_layout\": \"None\",\n",
      "  \"partition_schema\": \"None\",\n",
      "  \"all_reduce_dtype\": \"None\",\n",
      "  \"cast_logits_dtype\": \"None\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "line=\"\"\"model_id_or_path='/tmp/.djl.ai/download/ae03dd100c208acd82b5dbed563c971de864c408' rolling_batch=<RollingBatchEnum.auto: 'auto'> tensor_parallel_degree=8 trust_remote_code=False enable_streaming=<StreamingEnum.false: 'false'> batch_size=4 max_rolling_batch_size=4 dtype=<Dtype.f16: 'fp16'> revision=None output_formatter=None waiting_steps=None is_mpi=False draft_model_id=None spec_length=0 neuron_optimize_level=None enable_mixed_precision_accumulation=False enable_saturate_infinity=False n_positions=4096 unroll=None load_in_8bit=False low_cpu_mem_usage=False load_split_model=True context_length_estimate=None amp='f16' quantize=None compiled_graph_path=None task=None save_mp_checkpoint_path=None group_query_attention=None model_loader=<TnXModelLoaders.tnx: 'tnx'> rolling_batch_strategy=<TnXGenerationStrategy.continuous_batching: 'continuous_batching'> fuse_qkv=False on_device_embedding=False attention_layout=None collectives_layout=None cache_layout=None partition_schema=None all_reduce_dtype=None cast_logits_dtype=None\"\"\"\n",
    "import re\n",
    "import json\n",
    "pattern = r' (?=[^\\'\"])'\n",
    "\n",
    "\n",
    "# Split the string using the pattern\n",
    "result = re.split(pattern, line)\n",
    "print(\"\\n\".join([r for r in result]))\n",
    "params= {}\n",
    "for kv in result:\n",
    "    #print(kv.split('='))\n",
    "    k,v = kv.split('=')\n",
    "    params[k] = v\n",
    "print(json.dumps(params, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c6e72-c7d7-46ae-aec9-67400130120e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_fmbench_python311",
   "language": "python",
   "name": "conda_fmbench_python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
